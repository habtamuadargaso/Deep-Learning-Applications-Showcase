{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNm4gEwjx9eWRdqTXH13rBQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/habtamuadargaso/Deep-Learning-Applications-Showcase/blob/main/Image_predication_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Fn4cU7Kg4J12"
      },
      "outputs": [],
      "source": [
        "# import the kersa libraries and package\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "pIDaca9F4mu3"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialising the CNN\n",
        "classifier = Sequential()"
      ],
      "metadata": {
        "id": "ESoh3za15UrI"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Conv2D(32,(3,3), input_shape = (64, 64, 3), activation='relu'))"
      ],
      "metadata": {
        "id": "RYZS3jsd5s9k"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a second convlution layer\n",
        "classifier.add(Conv2D(32,(3,3),activation='relu'))\n",
        "# mapping and reducing to 2,2 pool_size ,\n",
        "classifier.add(MaxPooling2D(pool_size =(2,2)) )"
      ],
      "metadata": {
        "id": "ni3v6t48B2_v"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# step 3- Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# step 4- Fiull connection\n",
        "classifier.add(Dense(units=128, activation= 'relu'))\n",
        "# single out put to one\n",
        "classifier.add(Dense(units=1, activation= 'sigmoid'))\n"
      ],
      "metadata": {
        "id": "ztTmmGUDB2qt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the Cnn\n",
        "# classifier.compile(optimizer='adam', loss = 'binary_crossentropy', metrics= ['accuracy'])\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "eV0ZmAgVB2WQ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import train\n",
        "# part 2 - fitting the Cnn to the image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator( rescale= 1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                    zoom_range= 0.2,\n",
        "                                    horizontal_flip=True)"
      ],
      "metadata": {
        "id": "68r9LOn-B1pk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive to /content/drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRUK2EnzZA54",
        "outputId": "142ae5e2-3ce2-410f-eec2-dd96b01d8d48"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/archive (11)/train',\n",
        "                                                 target_size= (64,64),\n",
        "                                                 batch_size= 32,\n",
        "                                                 class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGZHLMDGPjXi",
        "outputId": "69bfdf52-a18e-4e55-c484-0ff48a1b6b6f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 328 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen = ImageDataGenerator( rescale= 1./255)\n",
        "test_set = train_datagen.flow_from_directory('/content/drive/MyDrive/archive (11)/test',\n",
        "                                                 target_size= (64,64),\n",
        "                                                 batch_size= 32,\n",
        "                                                 class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwMaOBKZaycB",
        "outputId": "96243650-2efe-475f-c8fb-ca517e8d2568"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_set = train_datagen.flow_from_directory('/content/drive/MyDrive/archive (11)/test',\n",
        "                                                 target_size= (64,64),\n",
        "                                                 batch_size= 32,\n",
        "                                                 class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ae-YaYOaOIw",
        "outputId": "9cc1a2d4-3596-4d2b-a305-a3aa0ddd9671"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 120 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y-vXMmD6yE-Y"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch=164,\n",
        "                         epochs = 10,\n",
        "                         validation_data= test_set,\n",
        "                         validation_steps=10)\n",
        "# train the model\n",
        "classifier.fit_generator(training_set, steps_per_epoch=len(training_set),epochs=10, validation_data=test_set, validation_steps=len(test_set))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_JcZpzvvx5Y",
        "outputId": "bd4231fc-1a9a-489d-be2f-aa4541fcc304"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-c7ef2d6cdb56>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  classifier.fit_generator(training_set,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "  4/164 [..............................] - ETA: 1:10 - loss: 0.1834 - accuracy: 0.9083"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1640 batches). You may need to use the repeat() function when building your dataset.\n",
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r164/164 [==============================] - 7s 26ms/step - loss: 0.1834 - accuracy: 0.9083 - val_loss: 4.7923e-08 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-c7ef2d6cdb56>:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  classifier.fit_generator(training_set, steps_per_epoch=len(training_set),epochs=10, validation_data=test_set, validation_steps=len(test_set))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 4s 943ms/step - loss: 1.2371e-09 - accuracy: 1.0000 - val_loss: 8.0397e-12 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 5s 1s/step - loss: 2.6585e-11 - accuracy: 1.0000 - val_loss: 4.1137e-13 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 4s 953ms/step - loss: 1.5712e-14 - accuracy: 1.0000 - val_loss: 3.6351e-14 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 3s 846ms/step - loss: 2.5322e-14 - accuracy: 1.0000 - val_loss: 2.6944e-15 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 3s 904ms/step - loss: 2.7663e-17 - accuracy: 1.0000 - val_loss: 2.8628e-18 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 5s 1s/step - loss: 9.1006e-17 - accuracy: 1.0000 - val_loss: 3.9356e-17 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 3s 932ms/step - loss: 6.3537e-17 - accuracy: 1.0000 - val_loss: 5.7143e-17 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 3s 826ms/step - loss: 1.2143e-18 - accuracy: 1.0000 - val_loss: 3.0184e-17 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 6s 2s/step - loss: 7.2081e-17 - accuracy: 1.0000 - val_loss: 3.6004e-18 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 5s 1s/step - loss: 1.6471e-17 - accuracy: 1.0000 - val_loss: 4.3091e-17 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7a19ecbff670>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, the output  indicates that the model is achieving very low training and validation loss, and perfect training and validation accuracy. This could be a sign of a well-trained model. However, it's crucial to also evaluate the model on completely new, unseen data to ensure its generalization performance. The low loss and high accuracy suggest that the model has learned the training data well, but it's essential to test it on different data to avoid overfitting."
      ],
      "metadata": {
        "id": "4iwbDPjhrC9N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# making new predication"
      ],
      "metadata": {
        "id": "njN4p6Q6aNuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image"
      ],
      "metadata": {
        "id": "OQYV5-2yrf_h"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import test\n",
        "from numpy.lib.type_check import imag\n",
        "test_image = image.load_img('/content/drive/MyDrive/archive (11)/test/cats/cat_1.jpg', target_size=(64,64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0 )\n",
        "reslut = classifier.predict(test_image)\n",
        "training_set.class_indices\n",
        "\n",
        "if reslut[0][0] == 1:\n",
        "  Prediction = 'dog'\n",
        "else:\n",
        "    Prediction = 'cat'\n",
        "print(Prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Jmw90stOrvBo",
        "outputId": "8fe82c32-5516-4da2-cf36-27b3a3237385"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-3dcbff61b651>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0mreslut\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mPrediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dog'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    }
  ]
}